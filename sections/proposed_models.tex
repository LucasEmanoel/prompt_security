\begin{table*}[!ht]
  \small 
  \renewcommand{\arraystretch}{1.3}
  \setlength{\extrarowheight}{2pt}
  \caption{Comparison of Related Works on Prompt Injection Defense in LLMs}
  \label{tab:related_works}
  \begin{tabularx}{\textwidth}{
      >{\raggedright\arraybackslash}p{0.15\textwidth}
      >{\raggedright\arraybackslash}X
      >{\raggedright\arraybackslash}p{0.18\textwidth}
      >{\raggedright\arraybackslash}p{0.18\textwidth}
      >{\raggedright\arraybackslash}p{0.20\textwidth}}
    \toprule
    \textbf{Referencia} & \textbf{Foco} & \textbf{Metodologia} 
      & \textbf{Métricas} & \textbf{Lacuna} \\
    \midrule

      Lin, Huawei \emph{et al.} \cite{Lin2025UniGuardian} 
      & Proposta de defesa unificada (UniGuardian) contra ataques de LLM (injeção, backdoor, adversariais).
      & Propõe um framework de detecção unificado para analisar prompts e saídas.
      & (1) auROC (Area Under the Receiver Operator Characteristic Curve) e (2) auPRC (Area Under the Precision-Recall Curve).
      & Falta de profundidade no que tange a ataques de backdoor mais complexos ou ofuscados, gerando falsos positivos. \\
      
      Hong, Hanbin \emph{et al.} \cite{Hong2025SystematizationOfKnowledge} 
      & Sistematização do conhecimento em segurança de prompts em LLMs, propondo uma taxonomia e um conjunto de métricas próprias para padronizar avaliações de ataques e defesas.
      & Revisão sistemática e proposta de uma taxonomia multi-nível. Desenvolvimento de toolkit aberto e dataset (JailbreakDB) para avaliação padronizada.
      & Propõe métricas padronizadas próprias integradas a um toolkit de avaliação com taxonomia hierárquica e perfis de ameaça formais.
      & Limitação na aplicação prática das métricas e taxonomias propostas; necessidade de validação contínua e ampliação para modelos multimodais e cenários reais. \\

      Chen, Sizhe \emph{et al.} \cite{Chen2025StruQ}
      & Proposta de defesa chamada \textit{StruQ}, que utiliza consultas estruturadas (\textit{structured queries}) para separar dados do prompt, reduzindo o risco de injeções maliciosas em LLMs.
      & Implementação experimental com análise de desempenho e eficácia em diferentes cenários de injeção. Avalia a separação entre dados e instruções para mitigar ataques.
      & Taxa de sucesso de ataque, latência e sobrecarga do sistema (\textit{defense overhead}).
      & Boa eficácia em prompts simples, mas limitação em ataques indiretos e cenários complexos de múltiplas etapas, exigindo integração com outras técnicas de defesa. \\
      
    \midrule
    \textbf{This Work}
      & \textbf{Análise comparativa de frameworks de defesa contra injeção de prompt em LLMs.}
      & \textbf{Prova de conceito e simulações baseadas em diferentes cenários de ataque.}
      & \textbf{Taxa de sucesso de ataque, resiliência e custo computacional.}
      & \textbf{Busca preencher a lacuna de falta de metodologia padronizada para comparação empírica entre defesas.} \\
    \bottomrule
  \end{tabularx}
\end{table*}

\section{Proposed Model}
\label{sec:proposed_model}
