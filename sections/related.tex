\section{Trabalhos Relacionados}
\label{sec:related_works}

\begin{table*}[!ht]
  \small 
  \renewcommand{\arraystretch}{1.3}
  \setlength{\extrarowheight}{2pt}
  \caption{Comparison of Related Works on Prompt Injection Defense in LLMs}
  \label{tab:related_works}
  \begin{tabularx}{\textwidth}{
      >{\raggedright\arraybackslash}p{0.15\textwidth}
      >{\raggedright\arraybackslash}X
      >{\raggedright\arraybackslash}p{0.18\textwidth}
      >{\raggedright\arraybackslash}p{0.18\textwidth}
      >{\raggedright\arraybackslash}p{0.20\textwidth}}
    \toprule
    \textbf{Referencia} & \textbf{Foco} & \textbf{Metodologia} 
      & \textbf{Métricas} & \textbf{Lacuna} \\
    \midrule

      Lin, Huawei \emph{et al.} \cite{Lin2025UniGuardian} 
      & Proposta de defesa unificada (UniGuardian) contra ataques de LLM (injeção, backdoor, adversariais).
      & Propõe um framework de detecção unificado para analisar prompts e saídas.
      & (1) auROC (Area Under the Receiver Operator Characteristic Curve) e (2) auPRC (Area Under the Precision-Recall Curve).
      & Falta de profundidade no que tange a ataques de backdoor mais complexos ou ofuscados, gerando falsos positivos. \\
    \midrule
      Hong, Hanbin \emph{et al.} \cite{Hong2025SystematizationOfKnowledge} 
      & Sistematização do conhecimento em segurança de prompts em LLMs, propondo uma taxonomia e um conjunto de métricas próprias para padronizar avaliações de ataques e defesas.
      & Revisão sistemática e proposta de uma taxonomia multi-nível. Desenvolvimento de toolkit aberto e dataset (JailbreakDB) para avaliação padronizada.
      & Propõe métricas padronizadas próprias integradas a um toolkit de avaliação com taxonomia hierárquica e perfis de ameaça formais.
      & Limitação na aplicação prática das métricas e taxonomias propostas; necessidade de validação contínua e ampliação para modelos multimodais e cenários reais. \\
    \midrule
      Chen, Sizhe \emph{et al.} \cite{Chen2025StruQ}
      & Proposta de defesa chamada \textit{StruQ}, que utiliza consultas estruturadas (\textit{structured queries}) para separar dados do prompt, reduzindo o risco de injeções maliciosas em LLMs.
      & Implementação experimental com análise de desempenho e eficácia em diferentes cenários de injeção. Avalia a separação entre dados e instruções para mitigar ataques.
      & Taxa de sucesso de ataque, latência e sobrecarga do sistema (\textit{defense overhead}).
      & Boa eficácia em prompts simples, mas limitação em ataques indiretos e cenários complexos de múltiplas etapas, exigindo integração com outras técnicas de defesa. \\
      
    \midrule
      Benjamin, Victoria \emph{et al.} \cite{benjamin2024}
      & Análise sistemática da vulnerabilidade de 36 LLMs a ataques de injeção de prompt focados em gerar código de keylogger.
      & 4 prompts de injeção direta contra 36 LLMs. Análise estatística (Correlação, Random Forest, SHAP, PCA).
      & (1) Taxa de sucesso (2) Importância de features. (3) Correlação entre prompts.
      & Necessidade de testes multilíngues, múltiplas etapas de complexidade. \\
    \midrule
      Sebastian, Glorin. \cite{Sebastian2023SecurityUserInformation:}
      & Investigar a proteção de dados e privacidade em chatbots (foco no ChatGPT). Avaliar Tecnologias de Aprimoramento de Privacidade (PETs).
      & Revisão da literatura, análise de técnicas (ex: privacidade diferencial) e uma pesquisa (survey) com 177 usuários.
      & Métricas de percepção da pesquisa: (1) Nível de preocupação, (2) Disposição para sacrificar desempenho, (3) Consciência sobre vazamentos.
      & Análise de riscos à privacidade, preocupação dos usuários através de pesquisas. \\
    \midrule
    \textbf{This Work}
      & \textbf{}
      & \textbf{}
      & \textbf{}
      & \textbf{} \\
    \bottomrule
  \end{tabularx}
\end{table*}