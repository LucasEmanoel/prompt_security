# SeguranÃ§a de Prompts em Modelos de LLMs

Este repositÃ³rio contÃ©m o planejamento, a implementaÃ§Ã£o e a pesquisa para um projeto focado na **SeguranÃ§a de Prompts em Modelos de Linguagem de Grande Escala (LLMs)**. O objetivo principal Ã© desenvolver uma arquitetura robusta que proteja as interaÃ§Ãµes com LLMs contra ataques, como injeÃ§Ã£o de prompt.

-----

## ğŸ›ï¸ Arquitetura

O sistema implementa uma arquitetura de microsserviÃ§os projetada para interceptar e analisar as requisiÃ§Ãµes do usuÃ¡rio antes e depois de serem processadas pelo LLM. O fluxo Ã© centralizado por um **Orquestrador**, que coordena a comunicaÃ§Ã£o entre os diferentes componentes de seguranÃ§a.

A arquitetura Ã© composta pelas seguintes entidades:

  * **UsuÃ¡rio:** A entidade que envia o prompt inicial.
  * **Orquestrador:** O cÃ©rebro do sistema. Ele recebe o prompt do usuÃ¡rio, o encaminha para o `Sanitizador` para validaÃ§Ã£o, envia o prompt limpo ao LLM e, por fim, passa a resposta do LLM para o `Output Guardrail` antes de devolvÃª-la ao usuÃ¡rio.
  * **Sanitizador (Sanitizer):** Um microsserviÃ§o responsÃ¡vel por analisar o prompt de entrada do usuÃ¡rio. Sua funÃ§Ã£o Ã© detectar e neutralizar potenciais ameaÃ§as, como injeÃ§Ãµes de prompt ou conteÃºdo malicioso.
  * **ServiÃ§o de LLM:** O modelo de linguagem (ex: API da OpenAI) que recebe o prompt sanitizado e gera a resposta.
  * **Output Guardrail:** Um microsserviÃ§o que filtra a saÃ­da do LLM. Ele garante que a resposta gerada pelo modelo seja segura, apropriada e nÃ£o contenha informaÃ§Ãµes confidenciais antes de ser exibida ao usuÃ¡rio.

-----

## ğŸ“ Estrutura do RepositÃ³rio

O projeto estÃ¡ organizado nas seguintes pastas principais:

```
/
â”œâ”€â”€ ğŸ“„ sections/
â”‚   â””â”€â”€ (Artigo cientÃ­fico do projeto em formato LaTeX)
â”‚
â”œâ”€â”€ ğŸ’» code/
â”‚   â”œâ”€â”€ orchestrator/     (MicrosserviÃ§o do Orquestrador) 
â”‚   â”œâ”€â”€ sanitizer/        (MicrosserviÃ§o do Sanitizador) 
â”‚   â””â”€â”€ guardrail/        (MicrosserviÃ§o do Output Guardrail) 
â”‚
â”œâ”€â”€ ğŸ“Š activity/
â”‚   â””â”€â”€ (Slides e materiais de apresentaÃ§Ã£o do projeto)
â”‚
â””â”€â”€ README.md
```

-----

## ğŸ› ï¸ Tecnologias Utilizadas

Este projeto foi construÃ­do utilizando as seguintes tecnologias:

  * **Linguagem:** Python 
  * **Framework API:** FastAPI & Uvicorn 
  * **ContÃªineres:** Docker 
  * **LLM:** API da OpenAI 
  * **DiagramaÃ§Ã£o:** Draw.io 

-----

## ğŸš€ Executando o Projeto

A arquitetura de microsserviÃ§os Ã© gerenciada com Docker Compose, facilitando a configuraÃ§Ã£o e execuÃ§Ã£o do ambiente.

1.  **PrÃ©-requisito:** Tenha o Docker e o Docker Compose instalados em sua mÃ¡quina.
2.  **Navegue atÃ© a pasta `code/`:**
    ```bash
    cd code
    ```
3.  **Construa e inicie os serviÃ§os:**
    ```bash
    docker-compose up --build
    ```
4.  Isso iniciarÃ¡ os trÃªs serviÃ§os principais em contÃªineres separados, conforme definido no `docker-compose.yml`:
      * `sanitizer_service` (porta: 8000) 
      * `orchestrator_service` (porta: 7000) 
      * `output_guardrail_service` (porta: 6000) 

-----

Aqui estÃ¡ uma versÃ£o **bem mais resumida**, direta e adequada para o README:

---

# ğŸ§ª Como Executar os Testes

## 1. Testes UnitÃ¡rios

Cada microsserviÃ§o possui seus prÃ³prios testes.
Execute dentro de cada pasta:

**Sanitizer**

```bash
cd code/sanitizer
pytest -v
```

**Guardrail**

```bash
cd code/guardrail
pytest -v
```

**Orchestrator**

```bash
cd code/orchestrator
pytest -v
```

**Resultados esperados:**

* Sanitizer: 11/11 testes aprovados
* Guardrail: 22/22 aprovados
* Orchestrator: 11/12 aprovados 
---

## 2. Testes de IntegraÃ§Ã£o (API)

1. Inicie todos os serviÃ§os:

```bash
cd code
docker-compose up --build
```

2. Rode os testes de integraÃ§Ã£o:

```bash
cd code/orchestrator
pytest -v -m integration
```

**Resultado esperado:** 17/17 testes aprovados (100%) 

---

## 3. Testes no Postman

1. Com a arquitetura rodando via Docker
2. Importe a coleÃ§Ã£o de testes
3. Rode via *Collection Runner*

**Comportamentos esperados:**

* Bloqueio de viÃ©s â†’ 400
* Bloqueio de delÃ­rios â†’ 400
* SanitizaÃ§Ã£o de dados sensÃ­veis â†’ 200 (texto limpo)
  (EvidÃªncias: pÃ¡ginas 11â€“13 do relatÃ³rio )

---

## ğŸ‘¥ Equipe

Este projeto foi desenvolvido pelo grupo "SeguranÃ§a de prompts em modelos de LLMS", composto por:

  * Juan Gustavo 
  * Lucas Emanoel 
  * Lucas Messias
  * JoÃ¡s Vitor
  * JoÃ£o Victor
